{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Manual with Creating token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Input dengan lebih dari dua segmen\n",
    "segments = [\n",
    "    \"What is photosynthesis?\",  # Segmen 1\n",
    "    \"Photosynthesis is the process by which plants convert sunlight into energy.\",  # Segmen 2\n",
    "    \"It occurs in the chloroplasts of plant cells.\"  # Segmen 3\n",
    "]\n",
    "\n",
    "# Encode masing-masing segmen\n",
    "encoded_segments = [tokenizer.encode(seg, add_special_tokens=False) for seg in segments]\n",
    "\n",
    "# Gabungkan segmen dengan [SEP] di antaranya\n",
    "input_ids = [tokenizer.cls_token_id]  # [CLS]\n",
    "token_type_ids = []  # Untuk menyimpan ID tipe token\n",
    "current_segment_id = 0\n",
    "\n",
    "for segment in encoded_segments:\n",
    "    input_ids.extend(segment + [tokenizer.sep_token_id])  # Tambahkan segmen dan [SEP]\n",
    "    token_type_ids.extend([current_segment_id] * (len(segment) + 1))  # Token Type IDs\n",
    "    current_segment_id += 1  # Pindah ke segmen berikutnya\n",
    "\n",
    "# Padding untuk mencapai panjang maksimum\n",
    "max_length = 50\n",
    "attention_mask = [1] * len(input_ids)  # Mask untuk token yang relevan\n",
    "\n",
    "# Tambahkan padding jika diperlukan\n",
    "while len(input_ids) < max_length:\n",
    "    input_ids.append(0)  # Token PAD\n",
    "    attention_mask.append(0)\n",
    "    token_type_ids.append(0)  # Token Type ID untuk padding\n",
    "\n",
    "# Pastikan panjangnya sesuai\n",
    "input_ids = input_ids[:max_length]\n",
    "attention_mask = attention_mask[:max_length]\n",
    "token_type_ids = token_type_ids[:max_length]\n",
    "\n",
    "# Konversi ke tensor PyTorch\n",
    "input_ids = torch.tensor([input_ids])\n",
    "attention_mask = torch.tensor([attention_mask])\n",
    "token_type_ids = torch.tensor([token_type_ids])\n",
    "\n",
    "# Output\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "print(\"Token Type IDs:\", token_type_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
