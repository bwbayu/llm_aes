{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Manual with Creating token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Input dengan lebih dari dua segmen\n",
    "segments = [\n",
    "    \"What is photosynthesis?\",  # Segmen 1\n",
    "    \"Photosynthesis is the process by which plants convert sunlight into energy.\",  # Segmen 2\n",
    "    \"It occurs in the chloroplasts of plant cells.\"  # Segmen 3\n",
    "]\n",
    "\n",
    "# Encode masing-masing segmen\n",
    "encoded_segments = [tokenizer.encode(seg, add_special_tokens=False) for seg in segments]\n",
    "\n",
    "# Gabungkan segmen dengan [SEP] di antaranya\n",
    "input_ids = [tokenizer.cls_token_id]  # [CLS]\n",
    "token_type_ids = []  # Untuk menyimpan ID tipe token\n",
    "current_segment_id = 0\n",
    "\n",
    "for segment in encoded_segments:\n",
    "    input_ids.extend(segment + [tokenizer.sep_token_id])  # Tambahkan segmen dan [SEP]\n",
    "    token_type_ids.extend([current_segment_id] * (len(segment) + 1))  # Token Type IDs\n",
    "    current_segment_id += 1  # Pindah ke segmen berikutnya\n",
    "\n",
    "# Padding untuk mencapai panjang maksimum\n",
    "max_length = 50\n",
    "attention_mask = [1] * len(input_ids)  # Mask untuk token yang relevan\n",
    "\n",
    "# Tambahkan padding jika diperlukan\n",
    "while len(input_ids) < max_length:\n",
    "    input_ids.append(0)  # Token PAD\n",
    "    attention_mask.append(0)\n",
    "    token_type_ids.append(0)  # Token Type ID untuk padding\n",
    "\n",
    "# Pastikan panjangnya sesuai\n",
    "input_ids = input_ids[:max_length]\n",
    "attention_mask = attention_mask[:max_length]\n",
    "token_type_ids = token_type_ids[:max_length]\n",
    "\n",
    "# Konversi ke tensor PyTorch\n",
    "input_ids = torch.tensor([input_ids])\n",
    "attention_mask = torch.tensor([attention_mask])\n",
    "token_type_ids = torch.tensor([token_type_ids])\n",
    "\n",
    "# Output\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "print(\"Token Type IDs:\", token_type_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding custom embedding to handle more than 2 segment in BERT model varian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AlbertModel\n",
    "\n",
    "class CustomAlbertModel(nn.Module):\n",
    "    def __init__(self, model_name='indobenchmark/indobert-lite-base-p2', num_token_types=3):\n",
    "        super().__init__()\n",
    "        # Load ALBERT model\n",
    "        self.albert = AlbertModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Replace token_type_embeddings to support more token types\n",
    "        self.albert.embeddings.token_type_embeddings = nn.Embedding(\n",
    "            num_embeddings=num_token_types, \n",
    "            embedding_dim=self.albert.config.hidden_size\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        # Pass through modified ALBERT model\n",
    "        return self.albert(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "# Create model instance\n",
    "model = CustomAlbertModel(num_token_types=3)\n",
    "\n",
    "# Test model\n",
    "input_ids = torch.randint(0, 30000, (4, 512))  # Example input\n",
    "attention_mask = torch.ones(4, 512)  # Example mask\n",
    "token_type_ids = torch.randint(0, 3, (4, 512))  # Example token types (0, 1, 2)\n",
    "\n",
    "output = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "print(output.last_hidden_state.shape)  # Should be (batch_size, sequence_length, hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Task Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, bert_model_name):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
    "        self.task1_head = nn.Linear(self.bert.config.hidden_size, 1)  # Output for Task 1\n",
    "        self.task2_head = nn.Linear(self.bert.config.hidden_size, 1)  # Output for Task 2\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, task):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        if task == 1:\n",
    "            return self.task1_head(cls_embedding)\n",
    "        elif task == 2:\n",
    "            return self.task2_head(cls_embedding)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_task1, batch_task2 in zip(loader_task1, loader_task2):\n",
    "        # Task 1\n",
    "        optimizer.zero_grad()\n",
    "        output1 = model(batch_task1['input_ids'], batch_task1['attention_mask'], task=1)\n",
    "        loss1 = criterion(output1, batch_task1['scores'])\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Task 2\n",
    "        optimizer.zero_grad()\n",
    "        output2 = model(batch_task2['input_ids'], batch_task2['attention_mask'], task=2)\n",
    "        loss2 = criterion(output2, batch_task2['scores'])\n",
    "        loss2.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk without separating segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "torch.set_printoptions(threshold=torch.inf)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-lite-base-p2')\n",
    "\n",
    "question = \"Apa yang anda ketahui mengenai kerajaan Majapahit? (Mengenai tempat, masa puncak kejayaan dan agama. Usahakan jawab dalam 2-4 kalimat)\"\n",
    "ref_answer = \"Majapahit adalah sebuah kerajaan yang berpusat di Jawa Timur, Indonesia. Kerajaan ini mencapai puncak kejayaannya dan menguasai wilayah di Nusantara pada masa kekuasaan Hayam Wuruk. Kerajaan Majapahit merupakan kerajaan Hindu - Budha terbesar dalam sejarah Indonesia.\"\n",
    "answer = \"Majapahit adalah sebuah kerajaan yang berpusat di Jawa Timur, Indonesia, yang pernah berdiri dari sekitar tahun 1293 hingga 1500 M. Kerajaan ini mencapai puncak kejayaannya menjadi kemaharajaan raya yang menguasai wilayah yang luas di Nusantara pada masa kekuasaan Hayam Wuruk, yang berkuasa dari tahun 1350 hingga 1389. Kerajaan Majapahit adalah kerajaan Hindu-Buddha terakhir yang menguasai Nusantara dan dianggap sebagai salah satu dari negara terbesar dalam sejarah Indonesia.[2] Menurut Negarakertagama, kekuasaannya terbentang di Jawa, Sumatra, Semenanjung Malaya, Kalimantan, hingga Indonesia timur, meskipun wilayah kekuasaannya masih diperdebatkan. Sebelum berdirinya Majapahit, Singhasari telah menjadi kerajaan paling kuat di Jawa. Hal ini menjadi perhatian Kubilai Khan, penguasa Dinasti Yuan di Tiongkok. Ia mengirim utusan yang bernama Meng Chi[14] ke Singhasari yang menuntut upeti. Kertanagara, penguasa kerajaan Singhasari yang terakhir menolak untuk membayar upeti dan mempermalukan utusan tersebut dengan merusak wajahnya dan memotong telinganya.[14][15] Kubilai Khan marah dan lalu memberangkatkan ekspedisi besar ke Jawa tahun 1293. Ketika itu, Jayakatwang, adipati Kediri, sudah menggulingkan dan membunuh Kertanegara. Atas saran Aria Wiraraja, Jayakatwang memberikan pengampunan kepada Raden Wijaya, menantu Kertanegara, yang datang menyerahkan diri. Kemudian, Wiraraja mengirim utusan ke Daha, yang membawa surat berisi pernyataan, Raden Wijaya menyerah dan ingin mengabdi kepada Jayakatwang.[16] Jawaban dari surat di atas disambut dengan senang hati.[16] Raden Wijaya kemudian diberi hutan Tarik. Ia membuka hutan itu dan membangun desa baru. Desa itu dinamai Majapahit, yang namanya diambil dari buah maja, dan rasa 'pahit' dari buah tersebut. Ketika pasukan Mongol tiba, Wijaya bersekutu dengan pasukan Mongol untuk bertempur melawan Jayakatwang. Setelah berhasil menjatuhkan Jayakatwang, Raden Wijaya berbalik menyerang sekutu Mongolnya sehingga memaksa mereka menarik pulang kembali pasukannya secara kalang-kabut karena mereka berada di negeri asing.[17][18] Saat itu juga merupakan kesempatan terakhir mereka untuk menangkap angin muson agar dapat pulang, atau mereka terpaksa harus menunggu enam bulan lagi di pulau yang asing. Tanggal pasti yang digunakan sebagai tanggal kelahiran kerajaan Majapahit adalah hari penobatan Raden Wijaya sebagai raja, yaitu tanggal 15 bulan Kartika tahun 1215 saka yang bertepatan dengan tanggal 10 November 1293. Ia dinobatkan dengan nama resmi Kertarajasa Jayawardhana. Kerajaan ini menghadapi masalah. Beberapa orang terpercaya Kertarajasa, termasuk Ranggalawe, Sora, dan Nambi memberontak melawannya, meskipun pemberontakan tersebut tidak berhasil. Pemberontakan Ranggalawe ini didukung oleh Panji Mahajaya, Ra Arya Sidi, Ra Jaran Waha, Ra Lintang, Ra Tosan, Ra Gelatik, dan Ra Tati. Semua ini tersebut disebutkan dalam Pararaton.[19] Slamet Muljana menduga bahwa mahapatih Halayudha lah yang melakukan konspirasi untuk menjatuhkan semua orang tepercaya raja, agar ia dapat mencapai posisi tertinggi dalam pemerintahan. Namun setelah kematian pemberontak terakhir (Kuti), Halayudha ditangkap dan dipenjara, dan lalu dihukum mati.[18] Wijaya meninggal dunia pada tahun 1309. Putra dan penerus Wijaya adalah Jayanegara. Pararaton menyebutnya Kala Gemet, yang berarti 'penjahat lemah'. Kira-kira pada suatu waktu dalam kurun pemerintahan Jayanegara, seorang pendeta Italia, Odorico da Pordenone mengunjungi keraton Majapahit di Jawa. Pada tahun 1328, Jayanegara dibunuh oleh tabibnya, Tanca. Ibu tirinya yaitu Gayatri Rajapatni seharusnya menggantikannya, akan tetapi Rajapatni memilih mengundurkan diri dari istana dan menjadi bhiksuni. Rajapatni menunjuk anak perempuannya Tribhuwana Wijayatunggadewi untuk menjadi ratu Majapahit. Pada tahun 1336, Tribhuwana menunjuk Gajah Mada sebagai Mahapatih, pada saat pelantikannya Gajah Mada mengucapkan Sumpah Palapa yang menunjukkan rencananya untuk melebarkan kekuasaan Majapahit dan membangun sebuah kemaharajaan. Selama kekuasaan Tribhuwana, kerajaan Majapahit berkembang menjadi lebih besar dan terkenal di kepulauan Nusantara. Tribhuwana berkuasa di Majapahit sampai kematian ibunya pada tahun 1350. Ia diteruskan oleh putranya, Hayam Wuruk.\"\n",
    "text = f\"Question: {question} Reference Answer: {ref_answer} [SEP] Student Answer: {answer}\"\n",
    "\n",
    "tokens = tokenizer.encode_plus(text, add_special_tokens=False, truncation=False, return_tensors='pt')\n",
    "\n",
    "token_type_ids = []\n",
    "current_token = 0\n",
    "for token in tokens['input_ids'].flatten():\n",
    "    if(token == 0):\n",
    "        token_type_ids.append(0)\n",
    "        continue\n",
    "    token_type_ids.append(current_token)\n",
    "    if(token == 102 or token == 3): # 102 is token SEP for bert-base and 3 is for albert-lite\n",
    "        current_token += 1\n",
    "\n",
    "input_ids = tokens['input_ids'].flatten()\n",
    "attention_mask = tokens['attention_mask'].flatten()\n",
    "token_type_ids = torch.tensor(token_type_ids)\n",
    "token_type_ids\n",
    "\n",
    "# chunking hierarkikal -> no overlapping\n",
    "chunks = []\n",
    "max_len = 512\n",
    "cls_token = torch.tensor([2]) # 101 untuk bert, 2 untuk indobert\n",
    "sep_token = torch.tensor([3]) # 102 untuk bert, 3 untuk indobert\n",
    "\n",
    "for i in range(0, len(input_ids), max_len):\n",
    "    chunk_input_ids = input_ids[i: i+max_len]\n",
    "    chunk_att_mask = attention_mask[i: i+max_len]\n",
    "    chunk_token_type = token_type_ids[i: i+max_len]\n",
    "\n",
    "    # menentukan segmen yang benar untuk token [CLS] dan [SEP] yang baru ditambahkan -> TANYA GPT LAGI NANTI\n",
    "    first_token_type = chunk_token_type[0].unsqueeze(0) \n",
    "    last_token_type = chunk_token_type[-1].unsqueeze(0) \n",
    "\n",
    "    # menambahkan token [CLS] diawal teks saja\n",
    "    if(i == 0):\n",
    "        chunk_input_ids = torch.cat([cls_token, chunk_input_ids])\n",
    "        chunk_att_mask = torch.cat([torch.ones(1, dtype=torch.long), chunk_att_mask])\n",
    "        chunk_token_type = torch.cat([first_token_type, chunk_token_type])\n",
    "    else:\n",
    "        # chunk sisanya tambahkan [SEP] diawal\n",
    "        chunk_input_ids = torch.cat([sep_token, chunk_input_ids])\n",
    "        chunk_att_mask = torch.cat([torch.ones(1, dtype=torch.long), chunk_att_mask])\n",
    "        chunk_token_type = torch.cat([first_token_type, chunk_token_type])\n",
    "\n",
    "    # Tambahkan [SEP] di akhir tiap chunk\n",
    "    chunk_input_ids = torch.cat([chunk_input_ids, sep_token])\n",
    "    chunk_att_mask = torch.cat([chunk_att_mask, torch.ones(1, dtype=torch.long)])\n",
    "    chunk_token_type = torch.cat([chunk_token_type, last_token_type])\n",
    "\n",
    "    # menambahkan padding pada chunk terakhir agar memastikan panjang tiap chunk itu sama\n",
    "    if len(chunk_input_ids) < max_len:\n",
    "        padding_length = max_len - len(chunk_input_ids)\n",
    "\n",
    "        # assign padding 0\n",
    "        chunk_input_ids = torch.cat([chunk_input_ids, torch.zeros(padding_length, dtype=torch.long)])\n",
    "        chunk_att_mask = torch.cat([chunk_att_mask, torch.zeros(padding_length, dtype=torch.long)])\n",
    "        chunk_token_type = torch.cat([chunk_token_type, torch.zeros(padding_length, dtype=torch.long)])\n",
    "\n",
    "    result = {\n",
    "        'input_ids': chunk_input_ids,\n",
    "        'attention_mask': chunk_att_mask,\n",
    "        'token_type_ids': chunk_token_type,\n",
    "    }\n",
    "\n",
    "    chunks.append(result)\n",
    "\n",
    "chunks\n",
    "# for item in chunks:\n",
    "#     print(len(item['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHUNK WITH SEGMENT SEPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Apa yang anda ketahui mengenai kerajaan Majapahit? (Mengenai tempat, masa puncak kejayaan dan agama. Usahakan jawab dalam 2-4 kalimat)\"\n",
    "ref_answer = \"Majapahit adalah sebuah kerajaan yang berpusat di Jawa Timur, Indonesia. Kerajaan ini mencapai puncak kejayaannya dan menguasai wilayah di Nusantara pada masa kekuasaan Hayam Wuruk. Kerajaan Majapahit merupakan kerajaan Hindu - Budha terbesar dalam sejarah Indonesia.\"\n",
    "answer = \"Majapahit adalah sebuah kerajaan yang berpusat di Jawa Timur, Indonesia, yang pernah berdiri dari sekitar tahun 1293 hingga 1500 M. Kerajaan ini mencapai puncak kejayaannya menjadi kemaharajaan raya yang menguasai wilayah yang luas di Nusantara pada masa kekuasaan Hayam Wuruk, yang berkuasa dari tahun 1350 hingga 1389. Kerajaan Majapahit adalah kerajaan Hindu-Buddha terakhir yang menguasai Nusantara dan dianggap sebagai salah satu dari negara terbesar dalam sejarah Indonesia.[2] Menurut Negarakertagama, kekuasaannya terbentang di Jawa, Sumatra, Semenanjung Malaya, Kalimantan, hingga Indonesia timur, meskipun wilayah kekuasaannya masih diperdebatkan. Sebelum berdirinya Majapahit, Singhasari telah menjadi kerajaan paling kuat di Jawa. Hal ini menjadi perhatian Kubilai Khan, penguasa Dinasti Yuan di Tiongkok. Ia mengirim utusan yang bernama Meng Chi[14] ke Singhasari yang menuntut upeti. Kertanagara, penguasa kerajaan Singhasari yang terakhir menolak untuk membayar upeti dan mempermalukan utusan tersebut dengan merusak wajahnya dan memotong telinganya.[14][15] Kubilai Khan marah dan lalu memberangkatkan ekspedisi besar ke Jawa tahun 1293. Ketika itu, Jayakatwang, adipati Kediri, sudah menggulingkan dan membunuh Kertanegara. Atas saran Aria Wiraraja, Jayakatwang memberikan pengampunan kepada Raden Wijaya, menantu Kertanegara, yang datang menyerahkan diri. Kemudian, Wiraraja mengirim utusan ke Daha, yang membawa surat berisi pernyataan, Raden Wijaya menyerah dan ingin mengabdi kepada Jayakatwang.[16] Jawaban dari surat di atas disambut dengan senang hati.[16] Raden Wijaya kemudian diberi hutan Tarik. Ia membuka hutan itu dan membangun desa baru. Desa itu dinamai Majapahit, yang namanya diambil dari buah maja, dan rasa 'pahit' dari buah tersebut. Ketika pasukan Mongol tiba, Wijaya bersekutu dengan pasukan Mongol untuk bertempur melawan Jayakatwang. Setelah berhasil menjatuhkan Jayakatwang, Raden Wijaya berbalik menyerang sekutu Mongolnya sehingga memaksa mereka menarik pulang kembali pasukannya secara kalang-kabut karena mereka berada di negeri asing.[17][18] Saat itu juga merupakan kesempatan terakhir mereka untuk menangkap angin muson agar dapat pulang, atau mereka terpaksa harus menunggu enam bulan lagi di pulau yang asing. Tanggal pasti yang digunakan sebagai tanggal kelahiran kerajaan Majapahit adalah hari penobatan Raden Wijaya sebagai raja, yaitu tanggal 15 bulan Kartika tahun 1215 saka yang bertepatan dengan tanggal 10 November 1293. Ia dinobatkan dengan nama resmi Kertarajasa Jayawardhana. Kerajaan ini menghadapi masalah. Beberapa orang terpercaya Kertarajasa, termasuk Ranggalawe, Sora, dan Nambi memberontak melawannya, meskipun pemberontakan tersebut tidak berhasil. Pemberontakan Ranggalawe ini didukung oleh Panji Mahajaya, Ra Arya Sidi, Ra Jaran Waha, Ra Lintang, Ra Tosan, Ra Gelatik, dan Ra Tati. Semua ini tersebut disebutkan dalam Pararaton.[19] Slamet Muljana menduga bahwa mahapatih Halayudha lah yang melakukan konspirasi untuk menjatuhkan semua orang tepercaya raja, agar ia dapat mencapai posisi tertinggi dalam pemerintahan. Namun setelah kematian pemberontak terakhir (Kuti), Halayudha ditangkap dan dipenjara, dan lalu dihukum mati.[18] Wijaya meninggal dunia pada tahun 1309. Putra dan penerus Wijaya adalah Jayanegara. Pararaton menyebutnya Kala Gemet, yang berarti 'penjahat lemah'. Kira-kira pada suatu waktu dalam kurun pemerintahan Jayanegara, seorang pendeta Italia, Odorico da Pordenone mengunjungi keraton Majapahit di Jawa. Pada tahun 1328, Jayanegara dibunuh oleh tabibnya, Tanca. Ibu tirinya yaitu Gayatri Rajapatni seharusnya menggantikannya, akan tetapi Rajapatni memilih mengundurkan diri dari istana dan menjadi bhiksuni. Rajapatni menunjuk anak perempuannya Tribhuwana Wijayatunggadewi untuk menjadi ratu Majapahit. Pada tahun 1336, Tribhuwana menunjuk Gajah Mada sebagai Mahapatih, pada saat pelantikannya Gajah Mada mengucapkan Sumpah Palapa yang menunjukkan rencananya untuk melebarkan kekuasaan Majapahit dan membangun sebuah kemaharajaan. Selama kekuasaan Tribhuwana, kerajaan Majapahit berkembang menjadi lebih besar dan terkenal di kepulauan Nusantara. Tribhuwana berkuasa di Majapahit sampai kematian ibunya pada tahun 1350. Ia diteruskan oleh putranya, Hayam Wuruk.\"\n",
    "text1 = f\"Question: {question} Reference Answer: {ref_answer}\"\n",
    "text2 = f\"Student Answer: {answer}\"\n",
    "\n",
    "tokens1 = tokenizer.encode_plus(text1, add_special_tokens=False, truncation=False, return_tensors='pt')\n",
    "tokens2 = tokenizer.encode_plus(text2, add_special_tokens=False, truncation=False, return_tensors='pt')\n",
    "\n",
    "def create_token_type(input_ids, segment_num):\n",
    "    token_type_ids = []\n",
    "    for token in input_ids:\n",
    "        if token == 0:\n",
    "            token_type_ids.append(0)\n",
    "            continue\n",
    "        token_type_ids.append(segment_num)\n",
    "    return torch.tensor(token_type_ids)\n",
    "\n",
    "# SEGMENT 1\n",
    "input_ids1 = tokens1['input_ids'].flatten()\n",
    "attention_mask1 = tokens1['attention_mask'].flatten()\n",
    "token_type_ids1 = create_token_type(input_ids1, 0)\n",
    "\n",
    "# SEGMENT 2\n",
    "input_ids2 = tokens2['input_ids'].flatten()\n",
    "attention_mask2 = tokens2['attention_mask'].flatten()\n",
    "token_type_ids2 = create_token_type(input_ids2, 1)\n",
    "\n",
    "# CREATE CHUNK WITHOUT OVERLAPPING -> HIERARKIKAL\n",
    "chunks = []\n",
    "max_len = 510\n",
    "cls_token = torch.tensor([2])\n",
    "sep_token = torch.tensor([3])\n",
    "\n",
    "def create_chunks(input_ids, attention_mask, token_type_ids, segment_num, stride=max_len):\n",
    "    chunk = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        print(i, i+max_len)\n",
    "        flag_padding = 0\n",
    "        chunk_input_ids = input_ids[i: i+max_len]\n",
    "        chunk_att_mask = attention_mask[i: i+max_len]\n",
    "        chunk_token_type = token_type_ids[i: i+max_len]\n",
    "\n",
    "        # Tambahkan token [CLS] khusus untuk segment dan chunk pertama \n",
    "        if(segment_num == 0 and i == 0):\n",
    "            chunk_input_ids = torch.cat([cls_token, chunk_input_ids])\n",
    "            chunk_att_mask = torch.cat([torch.ones(1, dtype=torch.long), chunk_att_mask])\n",
    "            chunk_token_type = torch.cat([torch.tensor([segment_num]), chunk_token_type])\n",
    "\n",
    "            # Tambahkan [SEP] di akhir tiap chunk\n",
    "            chunk_input_ids = torch.cat([chunk_input_ids, sep_token])\n",
    "            chunk_att_mask = torch.cat([chunk_att_mask, torch.ones(1, dtype=torch.long)])\n",
    "            chunk_token_type = torch.cat([chunk_token_type, torch.tensor([segment_num])])\n",
    "        else:\n",
    "            # Add token [SEP] di awal chunk seterusnya\n",
    "            chunk_input_ids = torch.cat([sep_token, chunk_input_ids])\n",
    "            chunk_att_mask = torch.cat([torch.ones(1, dtype=torch.long), chunk_att_mask])\n",
    "            chunk_token_type = torch.cat([torch.tensor([segment_num]), chunk_token_type])\n",
    "\n",
    "            # Tambahkan [SEP] di akhir tiap chunk\n",
    "            chunk_input_ids = torch.cat([chunk_input_ids, sep_token])\n",
    "            chunk_att_mask = torch.cat([chunk_att_mask, torch.ones(1, dtype=torch.long)])\n",
    "            chunk_token_type = torch.cat([chunk_token_type, torch.tensor([segment_num])])\n",
    "\n",
    "        # menambahkan padding pada chunk terakhir agar memastikan panjang tiap chunk itu sama\n",
    "        if len(chunk_input_ids) < max_len:\n",
    "            flag_padding = 1\n",
    "            padding_length = max_len - len(chunk_input_ids)\n",
    "\n",
    "            # assign padding 0\n",
    "            chunk_input_ids = torch.cat([chunk_input_ids, torch.zeros(padding_length, dtype=torch.long)])\n",
    "            chunk_att_mask = torch.cat([chunk_att_mask, torch.zeros(padding_length, dtype=torch.long)])\n",
    "            chunk_token_type = torch.cat([chunk_token_type, torch.zeros(padding_length, dtype=torch.long)])\n",
    "\n",
    "        chunk.append({\n",
    "            'input_ids': chunk_input_ids,\n",
    "            'attention_mask': chunk_att_mask,\n",
    "            'token_type_ids': chunk_token_type\n",
    "        })\n",
    "\n",
    "        if flag_padding == 1:\n",
    "            # stop stride chunk\n",
    "            break\n",
    "\n",
    "    return chunk\n",
    "\n",
    "# WITHOUT OVERLAPPING\n",
    "chunks_segment1 = create_chunks(input_ids1, attention_mask1, token_type_ids1, segment_num=0)\n",
    "chunks_segment2 = create_chunks(input_ids2, attention_mask2, token_type_ids2, segment_num=1)\n",
    "\n",
    "# WITH OVERLAPPING\n",
    "chunks_segment1 = create_chunks(input_ids1, attention_mask1, token_type_ids1, segment_num=0, stride=max_len-128)\n",
    "chunks_segment2 = create_chunks(input_ids2, attention_mask2, token_type_ids2, segment_num=1, stride=max_len-128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate FN for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_token_type_ids = []\n",
    "    all_scores = []\n",
    "\n",
    "    for chunks, score in batch:\n",
    "        for chunk in chunks:\n",
    "            all_input_ids.append(chunk['input_ids'])\n",
    "            all_attention_mask.append(chunk['attention_mask'])\n",
    "            all_token_type_ids.append(chunk['token_type_ids'])\n",
    "            all_scores.append(score)\n",
    "\n",
    "    return {\n",
    "        'input_ids': torch.stack(all_input_ids),\n",
    "        'attention_mask': torch.stack(all_attention_mask),\n",
    "        'token_type_ids': torch.stack(all_token_type_ids),\n",
    "        'scores': torch.tensor(all_scores, dtype=torch.float)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Fungsi collate untuk menangani batch data dengan beberapa chunk per sample dan memisahkan data dan label.\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Iterasi setiap sample dalam batch\n",
    "    for sample in batch:\n",
    "        # Setiap sample adalah tuple (data, label), kita pisahkan\n",
    "        data, label = sample\n",
    "        \n",
    "        # Data berisi list of dict (chunk-chunk untuk sample ini)\n",
    "        all_chunks.append(data)  # Menambahkan list of dict (chunks) ke all_chunks\n",
    "        all_labels.append(label)  # Menambahkan label ke all_labels\n",
    "\n",
    "    # Menggabungkan label menjadi tensor\n",
    "    all_labels_tensor = torch.stack(all_labels)  # Stack menjadi tensor (batch_size, 1)\n",
    "\n",
    "    return all_chunks, all_labels_tensor  # Mengembalikan batch data (chunks) dan labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Pooling with sum pooling and mask self-attention diagonal untuk menghindari self-attention (chunk memperhatikan dirinya sendiri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_pooling(self, chunk_outputs):\n",
    "    \"\"\"Menggabungkan output chunks menggunakan attention pooling dengan normalisasi.\"\"\"\n",
    "    # Normalisasi chunk embeddings\n",
    "    stacked_chunks = torch.nn.functional.normalize(torch.cat(chunk_outputs, dim=0), dim=1)  # [num_chunks, hidden_size]\n",
    "\n",
    "    # Hitung bobot perhatian\n",
    "    attention_scores = stacked_chunks @ stacked_chunks.T\n",
    "    attention_scores.fill_diagonal_(-float('inf'))  # Mask self-attention diagonal\n",
    "    attention_weights = torch.nn.functional.softmax(attention_scores, dim=1)\n",
    "\n",
    "    # Pooling dengan perhatian\n",
    "    pooled_output = attention_weights @ stacked_chunks\n",
    "\n",
    "    # Weighted sum pooling (mengganti mean pooling)\n",
    "    return torch.sum(pooled_output, dim=0)  # [hidden_size]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
