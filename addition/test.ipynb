{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[    2, 12444,   374, 24627,  8978, 11332,  6363, 29955,     3, 24627,\n",
      "          8978, 11332,  6363,   374,  1002,  9539,  2102, 19998, 15858, 29840,\n",
      "          2383, 17746,  2840, 18704, 26120, 10951, 29948,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      "Token Type IDs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      "Token Type Ids (Manual) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer1 = BertTokenizer.from_pretrained(\"indobenchmark/indobert-lite-base-p2\")\n",
    "\n",
    "# Input dengan dua segmen\n",
    "text = \"What is photosynthesis? [SEP] Photosynthesis is the process by which plants convert sunlight into energy.\"\n",
    "\n",
    "# Encode teks dengan token type IDs\n",
    "encoding = tokenizer1.encode_plus(\n",
    "    text,\n",
    "    add_special_tokens=True,  # Tambahkan [CLS] dan [SEP]\n",
    "    max_length=50,            # Panjang maksimum\n",
    "    padding='max_length',     # Tambahkan padding hingga max_length\n",
    "    truncation=True,          # Potong teks jika melebihi max_length\n",
    "    return_attention_mask=True,  # Kembalikan attention mask\n",
    "    return_token_type_ids=True,  # Kembalikan token type IDs\n",
    "    return_tensors='pt',      # Kembalikan tensor PyTorch\n",
    ")\n",
    "\n",
    "# Output\n",
    "print(\"Input IDs:\", encoding['input_ids'])\n",
    "print(\"Attention Mask:\", encoding['attention_mask'])\n",
    "print(\"Token Type IDs:\", encoding['token_type_ids'])\n",
    "\n",
    "# TOKEN TYPE ID MANUAL\n",
    "token_type_ids = []\n",
    "current_token = 0\n",
    "for token in encoding['input_ids'][0]:\n",
    "    if(token == 0):\n",
    "        token_type_ids.append(0)\n",
    "        continue\n",
    "    token_type_ids.append(current_token)\n",
    "    if(token == 102 or token == 3):\n",
    "        current_token += 1\n",
    "\n",
    "print(\"Token Type Ids (Manual)\", torch.tensor([token_type_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  3160,  1024, 23700,  2003, 17160,  1012,   102,  4431,  3437,\n",
      "          1024,  1038, 20470, 20470, 20470, 20470,  3363,  2497,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "tensor([  101,  3160,  1024, 23700,  2003, 17160,  1012,   102,  4431,  3437,\n",
      "         1024,  1038, 20470, 20470, 20470, 20470,  3363,  2497,   102,     0])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "text = \"Question : Neuroscience is fascinating. [SEP] Reference Answer : blablablablabllb\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(\n",
    "    text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=20,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "print(encoding)\n",
    "print(encoding['input_ids'].flatten())\n",
    "print(encoding['input_ids'].flatten().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101,  4431,  3437,  1024, 23700,  2003, 17160,  1012,   102,     0]])\n"
     ]
    }
   ],
   "source": [
    "text = \"Reference Answer : Neuroscience is fascinating.\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(\n",
    "    text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=10,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "print(\"Input IDs:\", encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  4431,  3437,  1024, 23700,  2003, 17160,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "encoded_input = tokenizer(text, max_length=550, truncation=True, padding='max_length', return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-tokens: ['neuroscience', 'is', 'fascinating', '.']\n",
      "Jumlah sub-token: 4\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Contoh teks\n",
    "text = \"Question: Neuroscience is fascinating.\"\n",
    "\n",
    "# Tokenisasi teks\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"Sub-tokens:\", tokens)\n",
    "print(\"Jumlah sub-token:\", len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST CHUNKING TEKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "torch.set_printoptions(threshold=torch.inf)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-lite-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Apa yang anda ketahui mengenai kerajaan Majapahit? (Mengenai tempat, masa puncak kejayaan dan agama. Usahakan jawab dalam 2-4 kalimat)\"\n",
    "ref_answer = \"Majapahit adalah sebuah kerajaan yang berpusat di Jawa Timur, Indonesia. Kerajaan ini mencapai puncak kejayaannya dan menguasai wilayah di Nusantara pada masa kekuasaan Hayam Wuruk. Kerajaan Majapahit merupakan kerajaan Hindu - Budha terbesar dalam sejarah Indonesia.\"\n",
    "answer = \"Majapahit adalah sebuah kerajaan yang berpusat di Jawa Timur, Indonesia, yang pernah berdiri dari sekitar tahun 1293 hingga 1500 M. Kerajaan ini mencapai puncak kejayaannya menjadi kemaharajaan raya yang menguasai wilayah yang luas di Nusantara pada masa kekuasaan Hayam Wuruk, yang berkuasa dari tahun 1350 hingga 1389. Kerajaan Majapahit adalah kerajaan Hindu-Buddha terakhir yang menguasai Nusantara dan dianggap sebagai salah satu dari negara terbesar dalam sejarah Indonesia.[2] Menurut Negarakertagama, kekuasaannya terbentang di Jawa, Sumatra, Semenanjung Malaya, Kalimantan, hingga Indonesia timur, meskipun wilayah kekuasaannya masih diperdebatkan. Sebelum berdirinya Majapahit, Singhasari telah menjadi kerajaan paling kuat di Jawa. Hal ini menjadi perhatian Kubilai Khan, penguasa Dinasti Yuan di Tiongkok. Ia mengirim utusan yang bernama Meng Chi[14] ke Singhasari yang menuntut upeti. Kertanagara, penguasa kerajaan Singhasari yang terakhir menolak untuk membayar upeti dan mempermalukan utusan tersebut dengan merusak wajahnya dan memotong telinganya.[14][15] Kubilai Khan marah dan lalu memberangkatkan ekspedisi besar ke Jawa tahun 1293. Ketika itu, Jayakatwang, adipati Kediri, sudah menggulingkan dan membunuh Kertanegara. Atas saran Aria Wiraraja, Jayakatwang memberikan pengampunan kepada Raden Wijaya, menantu Kertanegara, yang datang menyerahkan diri. Kemudian, Wiraraja mengirim utusan ke Daha, yang membawa surat berisi pernyataan, Raden Wijaya menyerah dan ingin mengabdi kepada Jayakatwang.[16] Jawaban dari surat di atas disambut dengan senang hati.[16] Raden Wijaya kemudian diberi hutan Tarik. Ia membuka hutan itu dan membangun desa baru. Desa itu dinamai Majapahit, yang namanya diambil dari buah maja, dan rasa 'pahit' dari buah tersebut. Ketika pasukan Mongol tiba, Wijaya bersekutu dengan pasukan Mongol untuk bertempur melawan Jayakatwang. Setelah berhasil menjatuhkan Jayakatwang, Raden Wijaya berbalik menyerang sekutu Mongolnya sehingga memaksa mereka menarik pulang kembali pasukannya secara kalang-kabut karena mereka berada di negeri asing.[17][18] Saat itu juga merupakan kesempatan terakhir mereka untuk menangkap angin muson agar dapat pulang, atau mereka terpaksa harus menunggu enam bulan lagi di pulau yang asing. Tanggal pasti yang digunakan sebagai tanggal kelahiran kerajaan Majapahit adalah hari penobatan Raden Wijaya sebagai raja, yaitu tanggal 15 bulan Kartika tahun 1215 saka yang bertepatan dengan tanggal 10 November 1293. Ia dinobatkan dengan nama resmi Kertarajasa Jayawardhana. Kerajaan ini menghadapi masalah. Beberapa orang terpercaya Kertarajasa, termasuk Ranggalawe, Sora, dan Nambi memberontak melawannya, meskipun pemberontakan tersebut tidak berhasil. Pemberontakan Ranggalawe ini didukung oleh Panji Mahajaya, Ra Arya Sidi, Ra Jaran Waha, Ra Lintang, Ra Tosan, Ra Gelatik, dan Ra Tati. Semua ini tersebut disebutkan dalam Pararaton.[19] Slamet Muljana menduga bahwa mahapatih Halayudha lah yang melakukan konspirasi untuk menjatuhkan semua orang tepercaya raja, agar ia dapat mencapai posisi tertinggi dalam pemerintahan. Namun setelah kematian pemberontak terakhir (Kuti), Halayudha ditangkap dan dipenjara, dan lalu dihukum mati.[18] Wijaya meninggal dunia pada tahun 1309. Putra dan penerus Wijaya adalah Jayanegara. Pararaton menyebutnya Kala Gemet, yang berarti 'penjahat lemah'. Kira-kira pada suatu waktu dalam kurun pemerintahan Jayanegara, seorang pendeta Italia, Odorico da Pordenone mengunjungi keraton Majapahit di Jawa. Pada tahun 1328, Jayanegara dibunuh oleh tabibnya, Tanca. Ibu tirinya yaitu Gayatri Rajapatni seharusnya menggantikannya, akan tetapi Rajapatni memilih mengundurkan diri dari istana dan menjadi bhiksuni. Rajapatni menunjuk anak perempuannya Tribhuwana Wijayatunggadewi untuk menjadi ratu Majapahit. Pada tahun 1336, Tribhuwana menunjuk Gajah Mada sebagai Mahapatih, pada saat pelantikannya Gajah Mada mengucapkan Sumpah Palapa yang menunjukkan rencananya untuk melebarkan kekuasaan Majapahit dan membangun sebuah kemaharajaan. Selama kekuasaan Tribhuwana, kerajaan Majapahit berkembang menjadi lebih besar dan terkenal di kepulauan Nusantara. Tribhuwana berkuasa di Majapahit sampai kematian ibunya pada tahun 1350. Ia diteruskan oleh putranya, Hayam Wuruk.\"\n",
    "text1 = f\"Question: {question} Reference Answer: {ref_answer}\"\n",
    "text2 = f\"Student Answer: {answer}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = tokenizer.encode_plus(text1, add_special_tokens=False, truncation=False, return_tensors='pt')\n",
    "tokens2 = tokenizer.encode_plus(text2, add_special_tokens=False, truncation=False, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_token_type(input_ids, segment_num):\n",
    "    token_type_ids = []\n",
    "    for token in input_ids:\n",
    "        if token == 0:\n",
    "            token_type_ids.append(0)\n",
    "            continue\n",
    "        token_type_ids.append(segment_num)\n",
    "    return torch.tensor(token_type_ids)\n",
    "\n",
    "# SEGMENT 1\n",
    "input_ids1 = tokens1['input_ids'].flatten()\n",
    "attention_mask1 = tokens1['attention_mask'].flatten()\n",
    "token_type_ids1 = create_token_type(input_ids1, 0)\n",
    "\n",
    "# SEGMENT 2\n",
    "input_ids2 = tokens2['input_ids'].flatten()\n",
    "attention_mask2 = tokens2['attention_mask'].flatten()\n",
    "token_type_ids2 = create_token_type(input_ids2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 510\n",
      "0 510\n",
      "510 1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([    2, 29791, 29950,   387,    34,   145,  4224,  1092,  3590, 10345,\n",
       "          29955, 29942,  1092,   515, 29946,   890,  4194, 16071,    41,  1300,\n",
       "          29948,  8738,  1024,   112,   109, 29947,   401,  3341, 29943, 10948,\n",
       "           4012, 24045,     7, 29950, 10345,   154,   492,  3590,    34, 14180,\n",
       "             26,  1069,  1276, 29946,   300, 29948,  3590,    92,  1408,  4194,\n",
       "          16071,    57,    41,  4335,  1350,    26,  4825,   126,   890,  3486,\n",
       "           6851,    24, 17479, 11989, 29948,  3590, 10345,   407,  3590,  7157,\n",
       "          29947, 14526,  2805,   112,  1588,   300, 29948,     3,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]),\n",
       "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0])},\n",
       " {'input_ids': tensor([    3, 16608, 24045,     7, 29950, 10345,   154,   492,  3590,    34,\n",
       "          14180,    26,  1069,  1276, 29946,   300, 29946,    34,   746,  2894,\n",
       "             98,   947,   262, 17031, 29858,   733,  8631,     8, 29948,  3590,\n",
       "             92,  1408,  4194, 16071,    57,   234, 11599,  9052,     5,  2264,\n",
       "             34,  4335,  1350,    34,  1678,    26,  4825,   126,   890,  3486,\n",
       "           6851,    24, 17479, 11989, 29946,    34,  9740,    98,   262, 13621,\n",
       "          29854,   733, 20092, 29861, 29948,  3590, 10345,   154,  3590,  7157,\n",
       "          29947,  9780,  1668,    34,  4335,  4825,    41,  2295,   242,   427,\n",
       "            282,    98,   664,  2805,   112,  1588,   300, 29948, 29957,   109,\n",
       "          29959,   807,   664,  1555, 14950,   116, 29946, 17282, 26266,    26,\n",
       "           1069, 29946,  9853, 29946, 19968, 25958, 29832, 29946,  4165, 29946,\n",
       "            733,   300,  1276, 29946,  1863,  1350, 17282,   419, 27321, 29948,\n",
       "            560, 10887, 10345, 29946,  2618, 18215,    65,   351,   234,  3590,\n",
       "            711,  1541,    26,  1069, 29948,   269,    92,   234,  2598,  4620,\n",
       "            650, 10700, 29946,  6931, 10761, 21337,    26,  8380, 29948,   447,\n",
       "           3209, 12331,    34,  2639,    80,  9935, 29957,  1327, 29959,    43,\n",
       "           2618, 18215,    65,    34,  5653,   912,  7871, 29948, 21309,   192,\n",
       "           6711, 29832, 29946,  6931,  3590,  2618, 18215,    65,    34,  1668,\n",
       "           4270,    90,  3574,   912,  7871,    41, 19321, 12243, 12331,   256,\n",
       "             79,  5002,  7942,    41,  8409, 24676, 29948, 29957,  1327, 29959,\n",
       "          29957,   970, 29959,  4620,   650, 10700,  4700,    41,   629,   403,\n",
       "          22075, 12470,   421,    43,  1069,   262, 17031, 29858, 29948,   640,\n",
       "            137, 29946,  3743,  9166,  4975, 29946, 17209,  8016, 29946,   259,\n",
       "           1017, 29125,    41,  4323, 21309, 22859, 29948,   441,  3386,  4744,\n",
       "          29832,  9290, 19902, 29832, 29946,  3743,  9166,  4975,   651, 21353,\n",
       "            455,  8818, 12072, 29946, 22635, 21309, 22859, 29946,    34,  1095,\n",
       "           6296,   745, 29948,   682, 29946,  9290, 19902, 29832,  3209, 12331,\n",
       "             43,  1299, 29832, 29946,    34,  1882,  1387,  3264,  3760, 29946,\n",
       "           8818, 12072,  7512,    41,   561, 17538,   455,  3743,  9166,  4975,\n",
       "          29948, 29957,  1407, 29959,  2188,    98,  1387,    26,   441, 11562,\n",
       "             79,  3000,  1268, 29948, 29957,  1407, 29959,  8818, 12072,   682,\n",
       "           2804,  2794,  5418, 29948,   447,  2014,  2794,   137,    41,  2255,\n",
       "           1351,   440, 29948,  1351,   137, 19075, 10345, 29946,    34,  2739,\n",
       "           3137,    98,  1307,  2111, 29832, 29946,    41,  1214, 29941, 11053,\n",
       "          29941,    98,  1307,   256, 29948,   640,  3946, 20338,  3598, 29946,\n",
       "          12072,   357, 28786,    79,  3946, 20338,    90, 20630,  3424,  3743,\n",
       "           9166,  4975, 29948,   450,  1520, 11436,  3743,  9166,  4975, 29946,\n",
       "           8818, 12072, 14687,  4462, 11727, 20338,    57,   485,  8134,   267,\n",
       "           1292,  2984,   755, 21060,   339,  5569,  2692, 29947, 15385,   211,\n",
       "            267,  1004,    26,  1202,  2945, 29948, 29957,  1482, 29959, 29957,\n",
       "           1233, 29959,   305,   137,   186,   407,  1947,  1668,   267,    90,\n",
       "           6013,  3873,   524,    46,   579,   173,  2984, 29946,   158,   267,\n",
       "           6522,   308,  3016,  3963,   823,   423,    26,  1984,    34,  2945,\n",
       "          29948,  1110,  1195,    34,   781,   242,  1110,  4952,  3590, 10345,\n",
       "            154,   406,    97,  2232,  8818, 12072,   242,  2542, 29946,   451,\n",
       "           1110,   970,   823, 20400,   262, 16928, 29859, 16430,    34, 14431,\n",
       "             79,  1110,   740,  2938, 17031, 29858, 29948,   447, 21207,    79,\n",
       "            712,  1983, 21309,  9052,   887,  3743,  9638, 12660, 29948,  3590,\n",
       "             92,  3142,   805, 29948,   388,   232,  3076, 21309,  9052,   887,\n",
       "          29946,  1087, 21526, 28774, 29835, 29946,  5463, 29832, 29946,    41,\n",
       "            400,  2588, 25811,  3424,    57, 29946,  1863, 12334,   256,   119,\n",
       "           1520,     3]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'token_type_ids': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'input_ids': tensor([    3, 29948, 12334, 21526, 28774, 29835,    92,  5080,   213, 19155,\n",
       "           4262, 15695, 29946,  3849, 14056,  4384, 29834, 29946,  3849,  1119,\n",
       "              5,  2282, 29832, 29946,  3849, 19647, 29946,  3849, 20498,     5,\n",
       "          29946,  3849,  1468,  4980, 29946,    41,  3849,  4862, 29834, 29948,\n",
       "            366,    92,   256,  4515,   112,   383,  2630,    46, 29948, 29957,\n",
       "            426, 29959, 14862,   431,  5680, 12667,   313,  4262, 11242, 29847,\n",
       "            269,  7064, 10219, 29832,  1389,    34,   464, 22052,    90, 11436,\n",
       "            366,   232,  3669, 24830,   128,  2542, 29946,   579,   447,   173,\n",
       "           1408,  1602,  4552,   112,  2395, 29948,   449,   450,  3323, 18508,\n",
       "           1668, 29942,  3128, 29834, 29943, 29946,   269,  7064, 10219, 29832,\n",
       "           7177,    41, 23791, 29946,    41,   629, 11714,  1861, 29948, 29957,\n",
       "           1233, 29959, 12072,  1851,   594,   126,   262, 12898, 29861, 29948,\n",
       "           4326,    41, 13430, 12072,   154,  3743, 20533, 29948,   383,  2630,\n",
       "             46, 10894,  5569,  5536,    84, 29946,    34,  1404, 29941, 14252,\n",
       "           4067, 29941, 29948,  5157, 29947,  5157,   126,   607,   486,   112,\n",
       "          10028,  2395,  3743, 20533, 29946,   596,  9994,  5105, 29946,  6958,\n",
       "            730,  1552,   483,  2617,  9260,  1135,  4277, 12506, 10345,    26,\n",
       "           1069, 29948,   126,   262, 18107, 29862, 29946,  3743, 20533, 10561,\n",
       "            213, 21806,  6515,    27, 29946,   363,   856, 29948,  1066, 24346,\n",
       "             57,   451,  2266, 13482,  2542, 13133,   784,  3109,  6830,    57,\n",
       "          29946,   150,   638,  2542, 13133,   784,  1246, 13645,   745,    98,\n",
       "           6101,    41,   234,  4061,  2159,  1366, 29948,  2542, 13133,   784,\n",
       "           8847,   436, 21837, 10499,  5331, 12424, 12072,    33,  2692, 11301,\n",
       "          25384,    90,   234,  6469, 10345, 29948,   126,   262, 16875, 29863,\n",
       "          29946, 10499,  5331, 12424,  8847,  7005, 11046,   242,  4262, 11242,\n",
       "          29847, 29946,   126,   305, 13315,    57,  7005, 11046,  5385,  9109,\n",
       "          29668,    34,  1647,  9079,    90, 28327,  3486, 10345,    41,  2255,\n",
       "            492, 11599,  9052,     5, 29948,   776,  3486, 10499,  5331, 12424,\n",
       "          29946,  3590, 10345,  2016,   234,   216,   421,    41,  2558,    26,\n",
       "           5755,  4825, 29948, 10499,  5331, 12424,  9740,    26, 10345,   493,\n",
       "           3323,  5567,   126,   262, 13621, 29854, 29948,   447, 13721,   213,\n",
       "          16029, 29946,  6851,    24, 17479, 11989, 29948,     3,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]),\n",
       "  'token_type_ids': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0])}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE CHUNK WITHOUT OVERLAPPING -> HIERARKIKAL\n",
    "chunks = []\n",
    "max_len = 510\n",
    "cls_token = torch.tensor([2])\n",
    "sep_token = torch.tensor([3])\n",
    "\n",
    "def create_chunks(input_ids, attention_mask, token_type_ids, segment_num, stride=max_len):\n",
    "    chunk = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        print(i, i+max_len)\n",
    "        flag_padding = 0\n",
    "        chunk_input_ids = input_ids[i: i+max_len]\n",
    "        chunk_att_mask = attention_mask[i: i+max_len]\n",
    "        chunk_token_type = token_type_ids[i: i+max_len]\n",
    "\n",
    "        # Tambahkan token [CLS] khusus untuk segment dan chunk pertama \n",
    "        if(segment_num == 0 and i == 0):\n",
    "            chunk_input_ids = torch.cat([cls_token, chunk_input_ids])\n",
    "            chunk_att_mask = torch.cat([torch.ones(1, dtype=torch.long), chunk_att_mask])\n",
    "            chunk_token_type = torch.cat([torch.tensor([segment_num]), chunk_token_type])\n",
    "\n",
    "            # Tambahkan [SEP] di akhir tiap chunk\n",
    "            chunk_input_ids = torch.cat([chunk_input_ids, sep_token])\n",
    "            chunk_att_mask = torch.cat([chunk_att_mask, torch.ones(1, dtype=torch.long)])\n",
    "            chunk_token_type = torch.cat([chunk_token_type, torch.tensor([segment_num])])\n",
    "        else:\n",
    "            # Add token [SEP] di awal chunk seterusnya\n",
    "            chunk_input_ids = torch.cat([sep_token, chunk_input_ids])\n",
    "            chunk_att_mask = torch.cat([torch.ones(1, dtype=torch.long), chunk_att_mask])\n",
    "            chunk_token_type = torch.cat([torch.tensor([segment_num]), chunk_token_type])\n",
    "\n",
    "            # Tambahkan [SEP] di akhir tiap chunk\n",
    "            chunk_input_ids = torch.cat([chunk_input_ids, sep_token])\n",
    "            chunk_att_mask = torch.cat([chunk_att_mask, torch.ones(1, dtype=torch.long)])\n",
    "            chunk_token_type = torch.cat([chunk_token_type, torch.tensor([segment_num])])\n",
    "\n",
    "        # menambahkan padding pada chunk terakhir agar memastikan panjang tiap chunk itu sama\n",
    "        if len(chunk_input_ids) < max_len:\n",
    "            flag_padding = 1\n",
    "            padding_length = max_len - len(chunk_input_ids)\n",
    "\n",
    "            # assign padding 0\n",
    "            chunk_input_ids = torch.cat([chunk_input_ids, torch.zeros(padding_length, dtype=torch.long)])\n",
    "            chunk_att_mask = torch.cat([chunk_att_mask, torch.zeros(padding_length, dtype=torch.long)])\n",
    "            chunk_token_type = torch.cat([chunk_token_type, torch.zeros(padding_length, dtype=torch.long)])\n",
    "\n",
    "        chunk.append({\n",
    "            'input_ids': chunk_input_ids,\n",
    "            'attention_mask': chunk_att_mask,\n",
    "            'token_type_ids': chunk_token_type\n",
    "        })\n",
    "\n",
    "        if flag_padding == 1:\n",
    "            # stop stride chunk\n",
    "            break\n",
    "\n",
    "    return chunk\n",
    "\n",
    "chunks_segment1 = create_chunks(input_ids1, attention_mask1, token_type_ids1, segment_num=0, stride=max_len)\n",
    "chunks_segment2 = create_chunks(input_ids2, attention_mask2, token_type_ids2, segment_num=1, stride=max_len)\n",
    "chunks = chunks_segment1 + chunks_segment2\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 510\n",
      "0 510\n",
      "382 892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([    3, 16608, 24045,     7, 29950, 10345,   154,   492,  3590,    34,\n",
       "          14180,    26,  1069,  1276, 29946,   300, 29946,    34,   746,  2894,\n",
       "             98,   947,   262, 17031, 29858,   733,  8631,     8, 29948,  3590,\n",
       "             92,  1408,  4194, 16071,    57,   234, 11599,  9052,     5,  2264,\n",
       "             34,  4335,  1350,    34,  1678,    26,  4825,   126,   890,  3486,\n",
       "           6851,    24, 17479, 11989, 29946,    34,  9740,    98,   262, 13621,\n",
       "          29854,   733, 20092, 29861, 29948,  3590, 10345,   154,  3590,  7157,\n",
       "          29947,  9780,  1668,    34,  4335,  4825,    41,  2295,   242,   427,\n",
       "            282,    98,   664,  2805,   112,  1588,   300, 29948, 29957,   109,\n",
       "          29959,   807,   664,  1555, 14950,   116, 29946, 17282, 26266,    26,\n",
       "           1069, 29946,  9853, 29946, 19968, 25958, 29832, 29946,  4165, 29946,\n",
       "            733,   300,  1276, 29946,  1863,  1350, 17282,   419, 27321, 29948,\n",
       "            560, 10887, 10345, 29946,  2618, 18215,    65,   351,   234,  3590,\n",
       "            711,  1541,    26,  1069, 29948,   269,    92,   234,  2598,  4620,\n",
       "            650, 10700, 29946,  6931, 10761, 21337,    26,  8380, 29948,   447,\n",
       "           3209, 12331,    34,  2639,    80,  9935, 29957,  1327, 29959,    43,\n",
       "           2618, 18215,    65,    34,  5653,   912,  7871, 29948, 21309,   192,\n",
       "           6711, 29832, 29946,  6931,  3590,  2618, 18215,    65,    34,  1668,\n",
       "           4270,    90,  3574,   912,  7871,    41, 19321, 12243, 12331,   256,\n",
       "             79,  5002,  7942,    41,  8409, 24676, 29948, 29957,  1327, 29959,\n",
       "          29957,   970, 29959,  4620,   650, 10700,  4700,    41,   629,   403,\n",
       "          22075, 12470,   421,    43,  1069,   262, 17031, 29858, 29948,   640,\n",
       "            137, 29946,  3743,  9166,  4975, 29946, 17209,  8016, 29946,   259,\n",
       "           1017, 29125,    41,  4323, 21309, 22859, 29948,   441,  3386,  4744,\n",
       "          29832,  9290, 19902, 29832, 29946,  3743,  9166,  4975,   651, 21353,\n",
       "            455,  8818, 12072, 29946, 22635, 21309, 22859, 29946,    34,  1095,\n",
       "           6296,   745, 29948,   682, 29946,  9290, 19902, 29832,  3209, 12331,\n",
       "             43,  1299, 29832, 29946,    34,  1882,  1387,  3264,  3760, 29946,\n",
       "           8818, 12072,  7512,    41,   561, 17538,   455,  3743,  9166,  4975,\n",
       "          29948, 29957,  1407, 29959,  2188,    98,  1387,    26,   441, 11562,\n",
       "             79,  3000,  1268, 29948, 29957,  1407, 29959,  8818, 12072,   682,\n",
       "           2804,  2794,  5418, 29948,   447,  2014,  2794,   137,    41,  2255,\n",
       "           1351,   440, 29948,  1351,   137, 19075, 10345, 29946,    34,  2739,\n",
       "           3137,    98,  1307,  2111, 29832, 29946,    41,  1214, 29941, 11053,\n",
       "          29941,    98,  1307,   256, 29948,   640,  3946, 20338,  3598, 29946,\n",
       "          12072,   357, 28786,    79,  3946, 20338,    90, 20630,  3424,  3743,\n",
       "           9166,  4975, 29948,   450,  1520, 11436,  3743,  9166,  4975, 29946,\n",
       "           8818, 12072, 14687,  4462, 11727, 20338,    57,   485,  8134,   267,\n",
       "           1292,  2984,   755, 21060,   339,  5569,  2692, 29947, 15385,   211,\n",
       "            267,  1004,    26,  1202,  2945, 29948, 29957,  1482, 29959, 29957,\n",
       "           1233, 29959,   305,   137,   186,   407,  1947,  1668,   267,    90,\n",
       "           6013,  3873,   524,    46,   579,   173,  2984, 29946,   158,   267,\n",
       "           6522,   308,  3016,  3963,   823,   423,    26,  1984,    34,  2945,\n",
       "          29948,  1110,  1195,    34,   781,   242,  1110,  4952,  3590, 10345,\n",
       "            154,   406,    97,  2232,  8818, 12072,   242,  2542, 29946,   451,\n",
       "           1110,   970,   823, 20400,   262, 16928, 29859, 16430,    34, 14431,\n",
       "             79,  1110,   740,  2938, 17031, 29858, 29948,   447, 21207,    79,\n",
       "            712,  1983, 21309,  9052,   887,  3743,  9638, 12660, 29948,  3590,\n",
       "             92,  3142,   805, 29948,   388,   232,  3076, 21309,  9052,   887,\n",
       "          29946,  1087, 21526, 28774, 29835, 29946,  5463, 29832, 29946,    41,\n",
       "            400,  2588, 25811,  3424,    57, 29946,  1863, 12334,   256,   119,\n",
       "           1520,     3]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'token_type_ids': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'input_ids': tensor([    3, 21060,   339,  5569,  2692, 29947, 15385,   211,   267,  1004,\n",
       "             26,  1202,  2945, 29948, 29957,  1482, 29959, 29957,  1233, 29959,\n",
       "            305,   137,   186,   407,  1947,  1668,   267,    90,  6013,  3873,\n",
       "            524,    46,   579,   173,  2984, 29946,   158,   267,  6522,   308,\n",
       "           3016,  3963,   823,   423,    26,  1984,    34,  2945, 29948,  1110,\n",
       "           1195,    34,   781,   242,  1110,  4952,  3590, 10345,   154,   406,\n",
       "             97,  2232,  8818, 12072,   242,  2542, 29946,   451,  1110,   970,\n",
       "            823, 20400,   262, 16928, 29859, 16430,    34, 14431,    79,  1110,\n",
       "            740,  2938, 17031, 29858, 29948,   447, 21207,    79,   712,  1983,\n",
       "          21309,  9052,   887,  3743,  9638, 12660, 29948,  3590,    92,  3142,\n",
       "            805, 29948,   388,   232,  3076, 21309,  9052,   887, 29946,  1087,\n",
       "          21526, 28774, 29835, 29946,  5463, 29832, 29946,    41,   400,  2588,\n",
       "          25811,  3424,    57, 29946,  1863, 12334,   256,   119,  1520, 29948,\n",
       "          12334, 21526, 28774, 29835,    92,  5080,   213, 19155,  4262, 15695,\n",
       "          29946,  3849, 14056,  4384, 29834, 29946,  3849,  1119,     5,  2282,\n",
       "          29832, 29946,  3849, 19647, 29946,  3849, 20498,     5, 29946,  3849,\n",
       "           1468,  4980, 29946,    41,  3849,  4862, 29834, 29948,   366,    92,\n",
       "            256,  4515,   112,   383,  2630,    46, 29948, 29957,   426, 29959,\n",
       "          14862,   431,  5680, 12667,   313,  4262, 11242, 29847,   269,  7064,\n",
       "          10219, 29832,  1389,    34,   464, 22052,    90, 11436,   366,   232,\n",
       "           3669, 24830,   128,  2542, 29946,   579,   447,   173,  1408,  1602,\n",
       "           4552,   112,  2395, 29948,   449,   450,  3323, 18508,  1668, 29942,\n",
       "           3128, 29834, 29943, 29946,   269,  7064, 10219, 29832,  7177,    41,\n",
       "          23791, 29946,    41,   629, 11714,  1861, 29948, 29957,  1233, 29959,\n",
       "          12072,  1851,   594,   126,   262, 12898, 29861, 29948,  4326,    41,\n",
       "          13430, 12072,   154,  3743, 20533, 29948,   383,  2630,    46, 10894,\n",
       "           5569,  5536,    84, 29946,    34,  1404, 29941, 14252,  4067, 29941,\n",
       "          29948,  5157, 29947,  5157,   126,   607,   486,   112, 10028,  2395,\n",
       "           3743, 20533, 29946,   596,  9994,  5105, 29946,  6958,   730,  1552,\n",
       "            483,  2617,  9260,  1135,  4277, 12506, 10345,    26,  1069, 29948,\n",
       "            126,   262, 18107, 29862, 29946,  3743, 20533, 10561,   213, 21806,\n",
       "           6515,    27, 29946,   363,   856, 29948,  1066, 24346,    57,   451,\n",
       "           2266, 13482,  2542, 13133,   784,  3109,  6830,    57, 29946,   150,\n",
       "            638,  2542, 13133,   784,  1246, 13645,   745,    98,  6101,    41,\n",
       "            234,  4061,  2159,  1366, 29948,  2542, 13133,   784,  8847,   436,\n",
       "          21837, 10499,  5331, 12424, 12072,    33,  2692, 11301, 25384,    90,\n",
       "            234,  6469, 10345, 29948,   126,   262, 16875, 29863, 29946, 10499,\n",
       "           5331, 12424,  8847,  7005, 11046,   242,  4262, 11242, 29847, 29946,\n",
       "            126,   305, 13315,    57,  7005, 11046,  5385,  9109, 29668,    34,\n",
       "           1647,  9079,    90, 28327,  3486, 10345,    41,  2255,   492, 11599,\n",
       "           9052,     5, 29948,   776,  3486, 10499,  5331, 12424, 29946,  3590,\n",
       "          10345,  2016,   234,   216,   421,    41,  2558,    26,  5755,  4825,\n",
       "          29948, 10499,  5331, 12424,  9740,    26, 10345,   493,  3323,  5567,\n",
       "            126,   262, 13621, 29854, 29948,   447, 13721,   213, 16029, 29946,\n",
       "           6851,    24, 17479, 11989, 29948,     3,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]),\n",
       "  'token_type_ids': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0])}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_segment1 = create_chunks(input_ids1, attention_mask1, token_type_ids1, segment_num=0, stride=max_len-128)\n",
    "chunks_segment2 = create_chunks(input_ids2, attention_mask2, token_type_ids2, segment_num=1, stride=max_len-128)\n",
    "chunks_segment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training untuk config1 selesai dengan hasil 0.851\n",
      "Training untuk config2 selesai dengan hasil 0.819\n",
      "Training untuk config3 selesai dengan hasil 0.912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Nama file CSV\n",
    "file_csv = \"training_results.csv\"\n",
    "\n",
    "# Data hasil konfigurasi yang akan disimpan\n",
    "def save_results_to_csv(config, result):\n",
    "    # Buat DataFrame\n",
    "    df = pd.DataFrame([{\n",
    "        \"config\": config,\n",
    "        \"result\": result\n",
    "    }])\n",
    "    \n",
    "    # Jika file belum ada, tulis dengan header\n",
    "    if not os.path.isfile(file_csv):\n",
    "        df.to_csv(file_csv, index=False)\n",
    "    else:\n",
    "        # Jika file sudah ada, append data tanpa header\n",
    "        df.to_csv(file_csv, mode='a', header=False, index=False)\n",
    "\n",
    "# Simulasi training loop\n",
    "configurations = [\"config1\", \"config2\", \"config3\"]\n",
    "results = [0.851, 0.819, 0.912]\n",
    "\n",
    "for config, result in zip(configurations, results):\n",
    "    try:\n",
    "        # Simulasi proses training\n",
    "        print(f\"Training untuk {config} selesai dengan hasil {result}\")\n",
    "        save_results_to_csv(config, result)\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi error: {e}\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
