{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.training.bert_pipeline import TrainingBertPipeline\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22406 entries, 0 to 22405\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   question           4859 non-null   object \n",
      " 1   reference_answer   22406 non-null  object \n",
      " 2   answer             22406 non-null  object \n",
      " 3   score              22406 non-null  float64\n",
      " 4   dataset            22406 non-null  object \n",
      " 5   max_length1        22406 non-null  int64  \n",
      " 6   normalized_score   22406 non-null  float64\n",
      " 7   normalized_score2  22406 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/aes_dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [4]\n",
    "overlappings = [128]\n",
    "epochs_list = [1]\n",
    "learning_rates = [1e-5]\n",
    "idx = 0  # index untuk setiap kombinasi\n",
    "\n",
    "ROOT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration: config_id=0, batch_size=4, overlapping=128, epochs=1, learning_rate=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split dataset run...\n",
      "create dataset run...\n",
      "create dataloader run...\n",
      "====== Training Epoch 1/1 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\transformers\\models\\albert\\modeling_albert.py:404: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attention_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1294.7342, Train QWK: 0.1648\n",
      "Validation Loss: 1160.2607, Validation QWK: 0.0440\n",
      "Test Loss: 1131.6991, Test QWK: 0.0653\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    for overlapping in overlappings:\n",
    "        for num_epochs in epochs_list:\n",
    "            for lr in learning_rates:\n",
    "                config = {\n",
    "                    \"df\": df,\n",
    "                    \"model_name\": \"indobenchmark/indobert-lite-base-p2\",\n",
    "                    \"overlapping\": overlapping,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"epochs\": num_epochs,\n",
    "                    \"config_id\": idx\n",
    "                }\n",
    "\n",
    "                logging.info(\n",
    "                    f\"Running configuration: config_id={idx}, batch_size={batch_size}, \"\n",
    "                    f\"overlapping={overlapping}, epochs={num_epochs}, learning_rate={lr}\"\n",
    "                )\n",
    "                \n",
    "                print(\n",
    "                    f\"\\nRunning configuration: config_id={idx}, batch_size={batch_size}, \"\n",
    "                    f\"overlapping={overlapping}, epochs={num_epochs}, learning_rate={lr}\"\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    pipeline = TrainingBertPipeline(config, results, results_epoch)\n",
    "                    pipeline.run_training()\n",
    "\n",
    "                    # Save results\n",
    "                    # Dapatkan root project\n",
    "                    results_path = os.path.join(ROOT_DIR, \"experiments/results/results.csv\")\n",
    "                    results_epoch_path = os.path.join(ROOT_DIR, \"experiments/results/results_epoch.csv\")\n",
    "                    TrainingBertPipeline.save_csv(results, results_path)\n",
    "                    TrainingBertPipeline.save_csv(results_epoch, results_epoch_path)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error in config_id={idx}: {str(e)}\")\n",
    "                    print(f\"Error in config_id={idx}: {str(e)}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                finally:\n",
    "                    # Clear GPU memory after every configuration\n",
    "                    del pipeline.model\n",
    "                    del pipeline.tokenizer\n",
    "                    del pipeline.optimizer\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
