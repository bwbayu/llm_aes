{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "# \n",
    "from dataset import EssayDataset\n",
    "from longDataset import LongEssayDataset\n",
    "from bert_regression import BertRegressionModel\n",
    "from hierarchicalBert import HierarchicalBert\n",
    "from datasets import load_dataset\n",
    "# \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>max_length1</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>normalized_score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jelaskan kegunaan karbohidrat untuk tubuh kita.</td>\n",
       "      <td>Fungsi karbohidrat adalah sebagai pemasok ener...</td>\n",
       "      <td>sumber tenaga, pemanis alami, menjaga sistem i...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>analisis_essay</td>\n",
       "      <td>65</td>\n",
       "      <td>0.27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jelaskan kegunaan karbohidrat untuk tubuh kita.</td>\n",
       "      <td>Fungsi karbohidrat adalah sebagai pemasok ener...</td>\n",
       "      <td>sebagai sumber energi, pemanis alami, menjaga ...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>analisis_essay</td>\n",
       "      <td>66</td>\n",
       "      <td>0.21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jelaskan kegunaan karbohidrat untuk tubuh kita.</td>\n",
       "      <td>Fungsi karbohidrat adalah sebagai pemasok ener...</td>\n",
       "      <td>1. Sebagai energi. 2. Sebagai memperlancaar pe...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>analisis_essay</td>\n",
       "      <td>76</td>\n",
       "      <td>0.42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jelaskan kegunaan karbohidrat untuk tubuh kita.</td>\n",
       "      <td>Fungsi karbohidrat adalah sebagai pemasok ener...</td>\n",
       "      <td>untuk membuat kenyang, agar tidak lapar, agar ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>analisis_essay</td>\n",
       "      <td>67</td>\n",
       "      <td>0.18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jelaskan kegunaan karbohidrat untuk tubuh kita.</td>\n",
       "      <td>Fungsi karbohidrat adalah sebagai pemasok ener...</td>\n",
       "      <td>Karbohidrat mempunyai peran penting untuk pros...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>analisis_essay</td>\n",
       "      <td>105</td>\n",
       "      <td>0.82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "0  Jelaskan kegunaan karbohidrat untuk tubuh kita.   \n",
       "1  Jelaskan kegunaan karbohidrat untuk tubuh kita.   \n",
       "2  Jelaskan kegunaan karbohidrat untuk tubuh kita.   \n",
       "3  Jelaskan kegunaan karbohidrat untuk tubuh kita.   \n",
       "4  Jelaskan kegunaan karbohidrat untuk tubuh kita.   \n",
       "\n",
       "                                    reference_answer  \\\n",
       "0  Fungsi karbohidrat adalah sebagai pemasok ener...   \n",
       "1  Fungsi karbohidrat adalah sebagai pemasok ener...   \n",
       "2  Fungsi karbohidrat adalah sebagai pemasok ener...   \n",
       "3  Fungsi karbohidrat adalah sebagai pemasok ener...   \n",
       "4  Fungsi karbohidrat adalah sebagai pemasok ener...   \n",
       "\n",
       "                                              answer  score         dataset  \\\n",
       "0  sumber tenaga, pemanis alami, menjaga sistem i...   27.0  analisis_essay   \n",
       "1  sebagai sumber energi, pemanis alami, menjaga ...   21.0  analisis_essay   \n",
       "2  1. Sebagai energi. 2. Sebagai memperlancaar pe...   42.0  analisis_essay   \n",
       "3  untuk membuat kenyang, agar tidak lapar, agar ...   18.0  analisis_essay   \n",
       "4  Karbohidrat mempunyai peran penting untuk pros...   82.0  analisis_essay   \n",
       "\n",
       "   max_length1  normalized_score  normalized_score2  \n",
       "0           65              0.27                 27  \n",
       "1           66              0.21                 21  \n",
       "2           76              0.42                 42  \n",
       "3           67              0.18                 18  \n",
       "4          105              0.82                 82  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/aes_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dataset = df['dataset'].unique()\n",
    "splits = {}\n",
    "\n",
    "for subset in subset_dataset:\n",
    "    subset_df = df[df['dataset'] == subset]\n",
    "\n",
    "    # split dataset (70:20:10)\n",
    "    train, temp = train_test_split(subset_df, test_size=0.3, random_state=42)\n",
    "    valid, test = train_test_split(temp, test_size=0.3, random_state=42)\n",
    "\n",
    "    splits[subset] = {\n",
    "        'train': train,\n",
    "        'valid': valid,\n",
    "        'test': test,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.concat([splits[subset]['train'] for subset in subset_dataset])\n",
    "valid_dataset = pd.concat([splits[subset]['valid'] for subset in subset_dataset])\n",
    "test_dataset = pd.concat([splits[subset]['test'] for subset in subset_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter dataset by category\n",
    "# selected_category = \"analisis_essay\"\n",
    "# train_dataset = train_dataset[train_dataset['dataset'] == selected_category]\n",
    "# valid_dataset = valid_dataset[valid_dataset['dataset'] == selected_category]\n",
    "# test_dataset = test_dataset[test_dataset['dataset'] == selected_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# load indobert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-lite-base-p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dataset with overlapping 128 and max length 512\n",
    "train_data = LongEssayDataset(train_dataset, tokenizer, 512, 128)\n",
    "valid_data = LongEssayDataset(valid_dataset, tokenizer, 512, 128)\n",
    "test_data = LongEssayDataset(test_dataset, tokenizer, 512, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset to dataloader for creating batch size 4\n",
    "train_dataloader = DataLoader(train_data, batch_size=4, collate_fn=lambda x: list(zip(*x)))\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=4, collate_fn=lambda x: list(zip(*x)))\n",
    "test_dataloader = DataLoader(test_data, batch_size=4, collate_fn=lambda x: list(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model, optimizer, and loss function (MSE)\n",
    "model = HierarchicalBert(\"indobenchmark/indobert-lite-base-p2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "epochs = 1\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\transformers\\models\\albert\\modeling_albert.py:404: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attention_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 1269.8804\n",
      "Epoch 1/1, Validation Loss: 1197.6855\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch, targets in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        # \n",
    "        targets = torch.stack(targets).to(device)\n",
    "        # forward pass\n",
    "        predictions = model(batch).squeeze(1)\n",
    "        # compute loss\n",
    "        loss = criterion(predictions, targets)\n",
    "        total_train_loss += loss.item()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    total_valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, targets in valid_dataloader:\n",
    "            targets = torch.stack(targets).to(device)\n",
    "            \n",
    "            predictions = model(batch).squeeze(1)\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / len(valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_valid_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing phase\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, targets in test_dataloader:\n",
    "        targets = torch.stack(targets).to(device)\n",
    "        \n",
    "        predictions = model(batch).squeeze(1)\n",
    "        loss = criterion(predictions, targets)\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
